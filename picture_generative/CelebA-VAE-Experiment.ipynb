{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Reshape, Lambda, Dense, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'vae'\n",
    "run_id = '0001'\n",
    "data_name = 'faces'\n",
    "RUN_FOLDER = 'run/{}/'.format(section)\n",
    "RUN_FOLDER += '_'.join([run_id, data_name])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n",
    "\n",
    "\n",
    "DATA_FOLDER = '../data/celeb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = (128,128,3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "\n",
    "NUM_IMAGES = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
    "                                         , target_size = INPUT_DIM[:2]\n",
    "                                         , batch_size = BATCH_SIZE\n",
    "                                         , shuffle = True\n",
    "                                         , class_mode = 'input'\n",
    "                                         , subset = \"training\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variational AutoEncoder class\n",
    "\n",
    "class VAE():\n",
    "    def __init__(self, input_shape,\n",
    "                encoder_filters,\n",
    "                encoder_kernel_size,\n",
    "                encoder_strides,\n",
    "                decoder_filters,\n",
    "                decoder_kernel_size,\n",
    "                decoder_strides,\n",
    "                use_batchnorm,\n",
    "                use_dropout,\n",
    "                z_dim\n",
    "                ):\n",
    "        self.input_shape = input_shape\n",
    "        self.encoder_filters = encoder_filters\n",
    "        self.encoder_kernel_size = encoder_kernel_size\n",
    "        self.encoder_strides = encoder_strides\n",
    "        self.decoder_filters = decoder_filters\n",
    "        self.decoder_kernel_size = decoder_kernel_size\n",
    "        self.decoder_strides = decoder_strides\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.use_dropout = use_dropout\n",
    "        self.z_dim = z_dim\n",
    "        self._build()\n",
    "    \n",
    "    def _build_encoder(self):\n",
    "        #build the encoder model\n",
    "        encoder_input = Input(shape=self.input_shape)\n",
    "        x = encoder_input\n",
    "        for i in range(len(self.encoder_filters)):\n",
    "            x = Conv2D(filters=self.encoder_filters[i],\n",
    "                      kernel_size=self.encoder_kernel_size[i],\n",
    "                      strides=self.encoder_strides[i],\n",
    "                      padding='same')(x)\n",
    "            if self.use_batchnorm:\n",
    "                x = BatchNormalization()(x)\n",
    "            \n",
    "            x = LeakyReLU()(x)\n",
    "            \n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate=0.5)(x)\n",
    "        \n",
    "        self.shape_before_flattening = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        encoder_mu = Dense(self.z_dim)(x)\n",
    "        encoder_log_var = Dense(self.z_dim)(x)\n",
    "        encoder_intermediate_model = Model(encoder_input, (encoder_mu, encoder_log_var))\n",
    "        \n",
    "        def sample(args):\n",
    "            mu, log_var = args\n",
    "            epsilon = K.random_normal(shape=K.shape(mu), mean=0.0, stddev=1.0)\n",
    "            z = mu + K.exp(log_var/2)*epsilon\n",
    "            return z\n",
    "        \n",
    "        sampling_layer = Lambda(sample)([encoder_mu, encoder_log_var])\n",
    "        encoder_output = sampling_layer\n",
    "        encoder_model = Model(encoder_input, encoder_output)\n",
    "        \n",
    "        return encoder_input, encoder_output, encoder_mu, encoder_log_var, encoder_intermediate_model, encoder_model\n",
    "    \n",
    "    def _build_decoder(self):\n",
    "        \n",
    "        decoder_input = Input(shape=(self.z_dim,))\n",
    "        x = Dense(np.prod(self.shape_before_flattening))(decoder_input)\n",
    "        x = Reshape(self.shape_before_flattening)(x)\n",
    "        \n",
    "        for i in range(len(self.decoder_filters)):\n",
    "            x = Conv2DTranspose(filters=self.decoder_filters[i],\n",
    "                           kernel_size=self.decoder_kernel_size[i],\n",
    "                           strides=self.decoder_strides[i],\n",
    "                           padding='same')(x)\n",
    "            \n",
    "            if i < len(self.decoder_filters)-1:\n",
    "                if self.use_batchnorm:\n",
    "                    x = BatchNormalization()(x)\n",
    "\n",
    "                x = LeakyReLU()(x)\n",
    "\n",
    "                if self.use_dropout:\n",
    "                    x = Dropout(rate=0.5)(x)\n",
    "            else:\n",
    "                x = Activation('sigmoid')(x)\n",
    "                \n",
    "        decoder_output = x\n",
    "        \n",
    "        decoder_model = Model(decoder_input, decoder_output)\n",
    "        \n",
    "        return decoder_input, decoder_output, decoder_model\n",
    "                \n",
    "        \n",
    "            \n",
    "    \n",
    "    def _build(self):\n",
    "        #build the encoder and decoder models\n",
    "        \n",
    "        self.encoder_input, \\\n",
    "        self.encoder_output, \\\n",
    "        self.encoder_mu, \\\n",
    "        self.encoder_log_var, \\\n",
    "        self.encoder_intermediate_model, \\\n",
    "        self.encoder_model = self._build_encoder()\n",
    "        \n",
    "        self.decoder_input, \\\n",
    "        self.decoder_output, \\\n",
    "        self.decoder_model = self._build_decoder()\n",
    "        \n",
    "        #build the VAE model from the above two pieces\n",
    "        model_output = self.decoder_model(self.encoder_output)\n",
    "        self.model = Model(self.encoder_input, model_output)\n",
    "        \n",
    "    def compile(self, learning_rate, r_loss_factor=1000):\n",
    "        \n",
    "        def vae_r_loss(y_true, y_pred):\n",
    "            return K.mean(K.square(y_true-y_pred), axis=[1,2,3])\n",
    "        \n",
    "        def vae_kl_loss(y_true, y_pred):\n",
    "            kl_loss =  -0.5 * K.sum(1 + self.encoder_log_var - K.square(self.encoder_mu) - K.exp(self.encoder_log_var), axis = 1)\n",
    "            return kl_loss\n",
    "        \n",
    "        def vae_loss(y_true, y_pred):\n",
    "            r_loss = vae_r_loss(y_true, y_pred) * r_loss_factor\n",
    "            kl_loss = vae_kl_loss(y_true, y_pred)\n",
    "            return  r_loss + kl_loss\n",
    "        \n",
    "        self.model.compile(loss=vae_loss, optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "        \n",
    "    def train(self,x_train, batch_size, epochs):\n",
    "        self.model.fit(x_train, x_train, batch_size=batch_size, epochs=epochs)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(input_shape=INPUT_DIM,\n",
    "                 encoder_filters=[32, 64, 64, 64], \n",
    "                 encoder_kernel_size = [3, 3, 3, 3],\n",
    "                 encoder_strides=[2, 2, 2, 2],\n",
    "                 decoder_filters=[64, 64, 32, 3],\n",
    "                 decoder_kernel_size=[3, 3, 3, 3],\n",
    "                 decoder_strides=[2, 2, 2, 2],\n",
    "                use_batchnorm=True,\n",
    "                use_dropout=True,\n",
    "                z_dim=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64, 64, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 32)   0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 64)   0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 8, 64)     0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          819400      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          819400      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 200)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,732,944\n",
      "Trainable params: 1,732,496\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64, 64, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 32)   0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 64)   0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 8, 64)     0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          819400      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          819400      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,732,944\n",
      "Trainable params: 1,732,496\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder_intermediate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              823296    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 128, 128, 3)       867       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 917,123\n",
      "Trainable params: 916,803\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(learning_rate=0.001, r_loss_factor=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6332/6332 [==============================] - 10978s 2s/step - loss: 301.6087 - acc: 0.7465\n",
      "Epoch 2/200\n",
      "6332/6332 [==============================] - 3825s 604ms/step - loss: 256.3093 - acc: 0.7551\n",
      "Epoch 3/200\n",
      "6332/6332 [==============================] - 2823s 446ms/step - loss: 252.5169 - acc: 0.7549\n",
      "Epoch 4/200\n",
      "6332/6332 [==============================] - 2926s 462ms/step - loss: 250.4944 - acc: 0.7554\n",
      "Epoch 5/200\n",
      "6332/6332 [==============================] - 2728s 431ms/step - loss: 249.1268 - acc: 0.7558\n",
      "Epoch 6/200\n",
      "6332/6332 [==============================] - 2659s 420ms/step - loss: 248.3491 - acc: 0.7561\n",
      "Epoch 7/200\n",
      "6332/6332 [==============================] - 2519s 398ms/step - loss: 247.4449 - acc: 0.7568\n",
      "Epoch 8/200\n",
      "6332/6332 [==============================] - 2520s 398ms/step - loss: 247.1339 - acc: 0.7571\n",
      "Epoch 9/200\n",
      "6332/6332 [==============================] - 2392s 378ms/step - loss: 245.0631 - acc: 0.7592\n",
      "Epoch 18/200\n",
      "6332/6332 [==============================] - 2688s 424ms/step - loss: 245.2461 - acc: 0.7592\n",
      "Epoch 19/200\n",
      "6332/6332 [==============================] - 3533s 558ms/step - loss: 244.9685 - acc: 0.7594\n",
      "Epoch 20/200\n",
      "6332/6332 [==============================] - 2610s 412ms/step - loss: 245.0413 - acc: 0.7594\n",
      "Epoch 21/200\n",
      "6332/6332 [==============================] - 2602s 411ms/step - loss: 244.8682 - acc: 0.7594\n",
      "Epoch 22/200\n",
      "6332/6332 [==============================] - 2600s 411ms/step - loss: 244.8037 - acc: 0.7597\n",
      "Epoch 23/200\n",
      "6332/6332 [==============================] - 2548s 402ms/step - loss: 244.7580 - acc: 0.7597\n",
      "Epoch 24/200\n",
      "6332/6332 [==============================] - 2580s 407ms/step - loss: 244.6984 - acc: 0.7595\n",
      "Epoch 25/200\n",
      "6332/6332 [==============================] - 2632s 416ms/step - loss: 244.6263 - acc: 0.7598\n",
      "Epoch 26/200\n",
      "6332/6332 [==============================] - 2819s 445ms/step - loss: 244.6607 - acc: 0.7599\n",
      "Epoch 27/200\n",
      "6332/6332 [==============================] - 2848s 450ms/step - loss: 244.5969 - acc: 0.7598\n",
      "Epoch 28/200\n",
      "6332/6332 [==============================] - 2591s 409ms/step - loss: 244.4965 - acc: 0.7597\n",
      "Epoch 29/200\n",
      "6332/6332 [==============================] - 2576s 407ms/step - loss: 244.6258 - acc: 0.7596\n",
      "Epoch 30/200\n",
      "6332/6332 [==============================] - 2574s 407ms/step - loss: 244.3689 - acc: 0.7595\n",
      "Epoch 31/200\n",
      "6332/6332 [==============================] - 2603s 411ms/step - loss: 244.3118 - acc: 0.7593\n",
      "Epoch 32/200\n",
      "6332/6332 [==============================] - 2448s 387ms/step - loss: 244.3344 - acc: 0.7592\n",
      "Epoch 33/200\n",
      "6332/6332 [==============================] - 2908s 459ms/step - loss: 244.2747 - acc: 0.7592\n",
      "Epoch 34/200\n",
      "6332/6332 [==============================] - 2506s 396ms/step - loss: 244.1074 - acc: 0.7587\n",
      "Epoch 35/200\n",
      "6332/6332 [==============================] - 2509s 396ms/step - loss: 244.1007 - acc: 0.7582\n",
      "Epoch 36/200\n",
      "6332/6332 [==============================] - 2508s 396ms/step - loss: 244.1165 - acc: 0.7564\n",
      "Epoch 37/200\n",
      "6332/6332 [==============================] - 2468s 390ms/step - loss: 244.1042 - acc: 0.7541\n",
      "Epoch 38/200\n",
      "6332/6332 [==============================] - 2389s 377ms/step - loss: 243.9243 - acc: 0.7540\n",
      "Epoch 39/200\n",
      "6332/6332 [==============================] - 2339s 369ms/step - loss: 243.8058 - acc: 0.7541\n",
      "Epoch 40/200\n",
      "6332/6332 [==============================] - 2328s 368ms/step - loss: 243.9296 - acc: 0.7538\n",
      "Epoch 41/200\n",
      "6332/6332 [==============================] - 2346s 370ms/step - loss: 243.5356 - acc: 0.7540\n",
      "Epoch 50/200\n",
      "6332/6332 [==============================] - 2504s 395ms/step - loss: 243.7597 - acc: 0.7537\n",
      "Epoch 51/200\n",
      "6332/6332 [==============================] - 2487s 393ms/step - loss: 243.6824 - acc: 0.7538\n",
      "Epoch 52/200\n",
      "6332/6332 [==============================] - 2482s 392ms/step - loss: 243.6111 - acc: 0.7539\n",
      "Epoch 53/200\n",
      "6332/6332 [==============================] - 2468s 390ms/step - loss: 243.4274 - acc: 0.7540\n",
      "Epoch 54/200\n",
      "2752/6332 [============>.................] - ETA: 24:02 - loss: 243.6218 - acc: 0.7543"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b3780b171b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mdata_flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 10000\n",
    "EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "\n",
    "vae.model.fit_generator(\n",
    "            data_flow\n",
    "            , shuffle = True\n",
    "            , epochs = EPOCHS\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9d4a07736cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reconstruct inputs from test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_to_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_to_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexample_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "#reconstruct inputs from test set\n",
    "n_to_show = 10\n",
    "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
    "example_images = x_test[example_idx]\n",
    "\n",
    "z_points = vae.encoder_model.predict(example_images)\n",
    "\n",
    "reconst_images = vae.decoder_model.predict(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = example_images[i].squeeze()\n",
    "    ax = fig.add_subplot(2, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)   \n",
    "    ax.imshow(img, cmap='gray_r')\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = reconst_images[i].squeeze()\n",
    "    ax = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img, cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative",
   "language": "python",
   "name": "generative"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
